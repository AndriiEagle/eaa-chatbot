# Сравнительный анализ процессов трансформации данных

## Введение

В данном документе представлен детальный сравнительный анализ между теоретической моделью процессов обработки данных, описанной в исходной таблице, и их фактической реализацией в коде проекта. Анализ основан на исследовании исходного кода и выявлении соответствующих компонентов, реализующих каждый этап трансформации данных.

## Сравнительная таблица процессов

| Этап | Исходные данные | Теоретическая трансформация | Ожидаемый результат | Фактическая реализация | Файлы и функции | Оценка соответствия |
|------|----------------|--------------------------|-------------------|---------------------|----------------|-------------------|
| **Препроцессинг** | Текст запроса пользователя | Нормализация (удаление шума), анализ сложности текста | Подготовленный запрос (чистый, анализируемый) | Использование GPT-4o-mini для классификации запроса, переформулировки, выявления необходимости уточнения. Разделение сложных запросов на подвопросы. | `preprocessQuery` (src/utils/preprocessing/preprocessQuery.ts), `smartSplitQuestions` (src/utils/questionSplitting/splitQuestions.ts), `convertDescriptiveToQuestion` | ✅ Полное соответствие |
| **Эмбеддинг** | Препроцессированный текст | Преобразование через text-embedding-ada-002 (нейросеть OpenAI для создания эмбеддингов) | Вектор размером 1536 (векторное представление смысла текста) | Использование модели text-embedding-ada-002 через OpenAI API | `createEmbedding` (src/services/openaiService.ts), `EMBEDDING_MODEL = 'text-embedding-ada-002'` (src/config/environment.ts) | ✅ Полное соответствие |
| **Векторный поиск** | Эмбеддинг + база данных | Поиск по косинусной схожести + SQL-фильтрация по метаданным (язык, тэги и т.д.) | Список релевантных чанков (отрывков текста) с метаданными | Вызов хранимой процедуры Supabase `match_documents` с параметрами: эмбеддинг, ID датасета, порог схожести, максимальное количество результатов | `findRelevantChunks` (src/services/supabaseService.ts) | ✅ Полное соответствие |
| **Контекстуализация** | Релевантные чанки + история | Форматирование + приоритизация (на основе актуальности, близости к запросу и предыдущим вопросам) | Структурированный контекст для генерации ответа | Форматирование чанков + контекст из истории (последние сообщения текущей сессии, семантически похожие сообщения из истории, факты о пользователе) | `formatRAGContext` (src/utils/formatting/formatters.ts), `createContextForRequest` (src/utils/memory/summaryManager.ts) | ✅ Полное соответствие |
| **Формирование промпта** | Контекст + системные инструкции | Шаблонизация, вставка инструкций, добавление ролей (например: «Ты — эксперт») | Полный промпт для модели LLM | Сборка массива `messages` с системным промптом (STRICT_SYSTEM_PROMPT или CONCISE_SYSTEM_PROMPT) и контекстом | askController.ts (формирование массива messages), src/config/environment.ts (определение промптов) | ✅ Полное соответствие |
| **Генерация** | Готовый промпт | Обработка с помощью gpt-4o-mini (или другой модели) | Структурированный текстовый ответ | Использование модели gpt-4o-mini через OpenAI API с последующей обработкой для удаления технических артефактов | `generateCompletion` (src/services/openaiService.ts), `CHAT_MODEL = 'gpt-4o-mini'` (src/config/environment.ts), `formatJsonObjects` (src/utils/formatting/formatters.ts) | ✅ Полное соответствие |
| **Извлечение фактов** | Сообщения пользователя | Анализ значимых утверждений (NER, классификация, дедукция через LLM) | Набор ключевых фактов о пользователе или его намерениях | Автоматическое извлечение фактов о бизнесе при сохранении диалога + проактивное извлечение из информационных сообщений | `extractFactsFromUserMessage` (src/utils/memory/factManager.ts), `processBusinessInfo` (src/utils/business/businessInfoProcessor.ts) | ✅ Полное соответствие |
| **Саммаризация** | История взаимодействий | Обзор с помощью LLM, выявление главных тем, фильтрация повторов | Краткое, но содержательное резюме для восстановления контекста | Создание резюме диалога, списка ключевых тем и извлечение информации о бизнесе с помощью GPT-4o-mini | `updateSessionSummary` (src/utils/memory/summaryManager.ts) | ✅ Полное соответствие |

## Детальный анализ этапов

### 1. Препроцессинг

**Теоретическая модель:** Нормализация (удаление шума), анализ сложности текста для получения подготовленного запроса.

**Фактическая реализация:**
- Функция `preprocessQuery` использует модель GPT-4o-mini для:
  - Определения релевантности запроса к теме European Accessibility Act
  - Возможной переформулировки запроса для более эффективного поиска
  - Определения необходимости уточнения (если вопрос слишком общий)
  - Генерации уточняющих вопросов при необходимости
- Функция `smartSplitQuestions` анализирует сложность запроса и при необходимости:
  - Эвристически определяет, является ли вопрос коротким/одиночным
  - Пытается разделить запрос по вопросительным знакам
  - При необходимости использует GPT-4o-mini для семантического разделения на подвопросы
- Функция `convertDescriptiveToQuestion` преобразует описательные утверждения в вопросительную форму

**Соответствие:** Фактическая реализация полностью соответствует теоретической модели, предоставляя комплексную обработку запроса перед дальнейшими этапами.

### 2. Эмбеддинг

**Теоретическая модель:** Преобразование текста в векторное представление размером 1536 с помощью модели text-embedding-ada-002.

**Фактическая реализация:**
- Функция `createEmbedding` получает текст и создает для него векторное представление
- Использует модель, указанную в переменной `EMBEDDING_MODEL`
- В конфигурационном файле `environment.ts` эта переменная установлена в `'text-embedding-ada-002'`
- Возвращает массив чисел (вектор), стандартный размер которого для данной модели составляет 1536

**Соответствие:** Фактическая реализация полностью соответствует теоретической модели, используя указанную модель и возвращая вектор ожидаемой размерности.

### 3. Векторный поиск

**Теоретическая модель:** Поиск по косинусной схожести с применением SQL-фильтрации по метаданным для получения релевантных чанков.

**Фактическая реализация:**
- Функция `findRelevantChunks` принимает:
  - Эмбеддинг запроса
  - ID датасета
  - Порог схожести (по умолчанию 0.78)
  - Максимальное количество чанков
- Вызывает хранимую процедуру `match_documents` в Supabase, которая:
  - Выполняет поиск по косинусной схожести (реализация внутри Supabase)
  - Применяет фильтрацию по метаданным (dataset_id)
  - Возвращает отсортированный по релевантности список чанков с их содержимым и метаданными

**Соответствие:** Фактическая реализация соответствует теоретической модели. Хотя детали реализации косинусного сходства и SQL-фильтрации находятся внутри хранимой процедуры Supabase, параметры вызова и результаты соответствуют ожидаемым.

### 4. Контекстуализация

**Теоретическая модель:** Форматирование и приоритизация релевантных чанков и истории на основе актуальности и близости к запросу.

**Фактическая реализация:**
- Функция `formatRAGContext`:
  - Принимает массив чанков и вопрос пользователя
  - Предварительно обрабатывает каждый чанк для преобразования сложных структур данных в текст
  - Форматирует чанки в единый контекст с системным промптом
- Функция `createContextForRequest`:
  - Получает профиль пользователя (факты о бизнесе) и формирует из них контекст
  - Добавляет последние сообщения текущей сессии (до 10)
  - Ищет семантически похожие сообщения из истории пользователя
  - Объединяет все в структурированный контекст с рекомендациями по ответу
- В `askController` эти два источника контекста объединяются

**Соответствие:** Фактическая реализация полностью соответствует теоретической модели, обеспечивая комплексную контекстуализацию с учетом текущего запроса, истории и профиля пользователя.

### 5. Формирование промпта

**Теоретическая модель:** Шаблонизация контекста с системными инструкциями и определением ролей.

**Фактическая реализация:**
- В `askController` формируется массив `messages`:
  - Первый элемент с `role: 'system'` и содержимым `STRICT_SYSTEM_PROMPT` (для основных запросов) или `CONCISE_SYSTEM_PROMPT` (для множественных запросов)
  - Второй элемент с `role: 'user'` и содержимым объединенного контекста
- Системные промпты содержат:
  - Определение роли ("Ты — эксперт по European Accessibility Act (EAA) и веб-доступности")
  - Ограничения и инструкции ("отвечай ТОЛЬКО на основе предоставленного контекста")
  - Правила форматирования ответа (обработка списков, объектов)
  - Указания по указанию источников

**Соответствие:** Фактическая реализация полностью соответствует теоретической модели, обеспечивая структурированный промпт с четко определенной ролью и инструкциями.

### 6. Генерация

**Теоретическая модель:** Обработка промпта с помощью модели gpt-4o-mini для получения структурированного текстового ответа.

**Фактическая реализация:**
- Функции `generateCompletion` и `generateStreamingCompletion`:
  - Принимают массив сообщений и температуру
  - Используют модель, указанную в `CHAT_MODEL`
  - В конфигурационном файле `environment.ts` эта переменная установлена в `'gpt-4o-mini'`
  - Возвращают текстовый ответ или поток для потоковой передачи
- Полученный ответ дополнительно обрабатывается функцией `formatJsonObjects` для:
  - Удаления технических артефактов вроде `[object Object]`
  - Преобразования JSON-структур в читаемый текст
  - Замены технических ключей на более дружественные названия

**Соответствие:** Фактическая реализация полностью соответствует теоретической модели, используя указанную модель и обеспечивая дополнительную постобработку для улучшения качества ответа.

### 7. Извлечение фактов

**Теоретическая модель:** Анализ значимых утверждений пользователя для получения набора ключевых фактов о пользователе или его намерениях.

**Фактическая реализация:**
- Функция `extractFactsFromUserMessage`:
  - Вызывается автоматически при сохранении пары сообщений
  - Проверяет, содержит ли сообщение информацию о бизнесе
  - Использует GPT-4o-mini с промптом для извлечения бизнес-фактов (`business_type`, `business_location`, `business_size`, `business_digital_presence`, `business_sector`)
  - Сохраняет факты с уверенностью >= 0.5 в базу данных
- Функция `processBusinessInfo`:
  - Обрабатывает информационные сообщения о бизнесе без явного вопроса
  - Также использует LLM для извлечения фактов
  - Сохраняет факты и генерирует релевантный ответ на основе извлеченной информации
- Функция `analyzeUserData`:
  - Анализирует имеющиеся факты о пользователе
  - Определяет полноту данных и недостающую информацию
  - Генерирует специфические вопросы для уточнения

**Соответствие:** Фактическая реализация полностью соответствует теоретической модели, обеспечивая комплексный анализ утверждений пользователя и построение его профиля.

### 8. Саммаризация

**Теоретическая модель:** Обзор истории взаимодействий с помощью LLM для создания краткого, но содержательного резюме.

**Фактическая реализация:**
- Функция `updateSessionSummary`:
  - Вызывается после сохранения пары сообщений
  - Если сообщений достаточно (>= 4), получает все сообщения сессии
  - Использует GPT-4o-mini для:
    - Создания краткого резюме диалога (2-3 предложения)
    - Формирования списка из 3-5 ключевых тем диалога
    - Извлечения информации о бизнесе пользователя
  - Сохраняет результаты в базе данных для последующего использования

**Соответствие:** Фактическая реализация полностью соответствует теоретической модели, обеспечивая автоматическое создание содержательного резюме диалога.

## Дополнительные компоненты и оптимизации

### Обработка множественных запросов
Система способна эффективно обрабатывать сложные запросы, разбивая их на подвопросы и обрабатывая каждый параллельно. Это реализовано через:
- Семантическое разделение запросов с помощью LLM
- Параллельное выполнение векторного поиска и генерации для каждого подвопроса
- Объединение результатов в структурированный множественный ответ

### Персонализация на основе бизнес-профиля
Система активно использует извлеченные факты о бизнесе для персонализации ответов:
- Контекст дополняется сведениями о типе бизнеса, его размере и местоположении
- LLM получает инструкции адаптировать ответ под конкретный тип бизнеса
- При отсутствии достаточных данных генерируются уточняющие вопросы

### Управление потоками обработки
В зависимости от типа запроса система выбирает оптимальный путь обработки:
- Для информационных сообщений о бизнесе - извлечение фактов и генерация соответствующего ответа
- Для нерелевантных запросов - вежливый отказ с предложением альтернативных тем
- Для запросов, требующих уточнения - генерация уточняющих вопросов
- Для стандартных запросов - полная цепочка обработки с RAG

## Заключение

Проведенный анализ кода демонстрирует полное соответствие между теоретической моделью процессов трансформации данных и их фактической реализацией в проекте. Система реализует все описанные этапы с использованием современных технологий:

1. Использование языковых моделей (GPT-4o-mini, GPT-3.5-turbo) для интеллектуальной обработки на разных этапах
2. Применение векторных представлений текста (text-embedding-ada-002) для эффективного поиска
3. Интеграция с Supabase для хранения и векторного поиска данных
4. Персонализация взаимодействия на основе накопленных знаний о пользователе
5. Оптимизация обработки сложных запросов через параллельную обработку

Фактическая реализация не только соответствует теоретической модели, но и расширяет ее, добавляя дополнительные возможности для улучшения пользовательского опыта и качества ответов о European Accessibility Act. 